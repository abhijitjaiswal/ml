{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"#Importing required libraries\nfrom keras import layers, models\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy import ndimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3d6701e15181089a1c121dc386d749179e11eca6"},"cell_type":"code","source":"#Loading dataset as DataFrames using pandas\nsign_train = pd.read_csv(\"../input/sign_mnist_train.csv\")\nsign_test = pd.read_csv(\"../input/sign_mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1977abaec60bdf71b14fd04d143ff65c09e858be","collapsed":true},"cell_type":"code","source":"#Looking at the Dataset, it has 1st column has label and rest columns are pixels. \n#Let's check how many pixel does each row has.\nsign_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d11c65987a787b31eb10e4e64cda661c2acaddfc","collapsed":true},"cell_type":"code","source":"#Looking at out of this command it shows, there are 785 columns, out which 1 is label.\n#So, there are 784 pixels in each row\nsign_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"722fe96534c5972b0d9926c96fd2fee7762969c2","collapsed":true},"cell_type":"code","source":"#The \"shape\" shows us that there are 27455 rows, so we have 27455 records for training.\nsign_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e139d33780bef2066e5c2e6b0720fe23ed8cb7b4"},"cell_type":"code","source":"#We will need the actual values to work with, so lets get them in numpy arrays\nx_train = sign_train.iloc[:, 1:].values\ny_train = sign_train.iloc[:, 0].values\n\nx_test = sign_test.iloc[:, 1:].values\ny_test = sign_test.iloc[:, 0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aed83fa2c5f0f7dcce4e0bac2b809945f0636bd","collapsed":true},"cell_type":"code","source":"#Lets check how many labels we can classify our data into\n#Maximum value in the label\nmax([i for i in y_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"359f24fcc5f79eb2cab36373926ef614edd120d9","collapsed":true},"cell_type":"code","source":"#Minimum value in the label\nmin([i for i in y_test])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05ae5170af72a2ff4eada632ab3785f092928888"},"cell_type":"markdown","source":"There is a range of 0 to 24 values, out of which 9 is excluded as per documentation, number 25 is also excluded in the documentation, though our range of labels is 25, we are actually working with 24 labels.\n"},{"metadata":{"trusted":true,"_uuid":"7254ff08e9055a63517ee9e9c36beabd7890a6af","collapsed":true},"cell_type":"code","source":"#Let's see how the data looks\n#There are 784 pixels as 28*28 pixel image\nimg = np.array(x_train[0,:].reshape(28, 28))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1d803a0445b4fd8da9b008b829456f9eda5fc51","collapsed":true},"cell_type":"code","source":"#To just verify, lets check labels as well \ny_train[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"271d3cc264106b5cdf2e0bca1dacd38beacffba6"},"cell_type":"markdown","source":"The labels rightly says that its a 'D' and is matching the image."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ddfa8079aa31222eed766bf81ef838be8ca70cfc"},"cell_type":"code","source":"#One hot encoding with 25 dimensions\n#The following method helps to enable the label as one hot encoded values\ndef vectorize_sequence(labels, dimension=25):\n    results = np.zeros([len(labels), dimension])\n    for i, sequence in enumerate(labels):\n        results[i, sequence] = 1\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bbcb4b3fb1941a353740730cb8a4f75f6c50403","collapsed":true},"cell_type":"code","source":"#Getting max value from the image pixels\nmax(max([i for i in seq] for seq in x_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d405b2781db4ef297055e6011eb8808840f64915","collapsed":true},"cell_type":"code","source":"#We need to scale the pixel data to values between 0 to 1\n#As well as vectorize labels\n#Scaling train data\nx_train = x_train.astype('float32') / 255\ny_train = vectorize_sequence(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d79c02524dfcd261cb78eb7eb4090fbd2f258a5e"},"cell_type":"code","source":"#scaling test data\nx_test = x_test.astype('float32') / 255\ny_test = vectorize_sequence(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f455de2da6dfa0555fe64752195a1b295cd744cc","collapsed":true},"cell_type":"code","source":"#It's always better to keep some data to validate the trained model before we actually test with our test data\n#Lets keep some data to validate\nx_data = x_train[:20000,]\ny_data = y_train[:20000]\nx_data = x_data.reshape(x_data.shape[0], 28, 28, 1)\nx_val = x_train[20000:, ]\ny_val = y_train[20000:]\nx_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\nx_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e44ec8ecf559138a7853769a1be54aa27b2ce48","collapsed":true},"cell_type":"code","source":"#Lets desgin model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (5,5), activation='relu'))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(25, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9a0a54829a52a7ae5c7bc0411e7f8f80755047fc"},"cell_type":"code","source":"#Let's compile the model now\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3be89a4e95d6b50e8a4daa40a90f20c724eb99f0"},"cell_type":"code","source":"#Generally we can run the model for 20 epochs, but we will get stable results after 9-10 epochs\nresults = model.fit(x_data, y_data, epochs=10, batch_size=512, \n                    validation_data=(x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04be28c6b09ede5c51a92a2667513cd255328d4f","collapsed":true},"cell_type":"code","source":"#The \"results\" has history attribute which has historical values for loss and accuracy for all epochs\nresults.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89ee7c6431bdcfa29963b1d13c7621bc3220eac1","collapsed":true},"cell_type":"code","source":"#Let's plot the Training vs Validation Loss and Accuracy\n#Training vs Validation Loss\nepochs = len(results.history['acc'])+1\nplt.plot(range(1, epochs), results.history['acc'], 'b', label=\"Training Accuracy\")\nplt.plot(range(1, epochs), results.history['val_acc'], 'r', label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training vs Validation Accuracy\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31511b460d8431e39e4afac3321fc79115a385c2","collapsed":true},"cell_type":"code","source":"#Training vs Validation Accuracy\nplt.plot(range(1, epochs), results.history['loss'], 'b', label=\"Training Loss\")\nplt.plot(range(1, epochs), results.history['val_loss'], 'r', label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4b024dafc51472c741c3c7a6dcd85b3a3b648de"},"cell_type":"markdown","source":"By looking at Loss and Accuracy graphs and comparison, we see that the validation data and training data very close values till epoch number 9, so we can change the above model to use 9 epochs instead of 10. After 9 epochs the model is overfitting to specific patterns which we donot want."},{"metadata":{"trusted":true,"_uuid":"05c29935e5e87a6587faec0cc300df0c3441e849"},"cell_type":"code","source":"#Lets train with 9 epochs now\n#Redifining the model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (5,5), activation='relu'))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(25, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2de70034ffff6b56d27dd0dadea275b724077695"},"cell_type":"code","source":"#Recompiling the model now\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e301ee5444fa5486ef8ce68d4ed75b60bf5c79"},"cell_type":"code","source":"results = model.fit(x_data, y_data, epochs=9, batch_size=512, \n                    validation_data=(x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04c9c5d9ee6861b15168f74053dc673857814862"},"cell_type":"code","source":"#Let's test now with our test data\ntest_loss, test_acc = model.evaluate(x_test, y_test)\n#The above will give error, as our model expects data of the shape (a, 28, 28, b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ee8deed05851afcf981b3488a179c3ad31ec8ad","collapsed":true},"cell_type":"code","source":"#Let's reshape the test data as we have already reshaped training data\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79912abc3cb9e25ecad61e408998fc0ccb71168f","collapsed":true},"cell_type":"code","source":"#Now finally lets test the model with test data\ntest_loss, test_acc = model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c3dd74a17309a131b86ad7785036fdd6877e89a"},"cell_type":"code","source":"#To see the test loss\ntest_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29313448a3e507a1667542b2fb5f736b17bd1658"},"cell_type":"code","source":"#To see the test accuracy\ntest_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bd0d6299794ff1367e0b4c70179ecc3262857ef3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}